runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
ggplot(tweets, aes(x = airline_sentiment, fill = airline_sentiment)) +
geom_bar() +
facet_grid(. ~ airline) +
theme(axis.text.x = element_text(angle=65, vjust=0.6),
plot.margin = unit(c(3,0,3,0), "cm"))
ggplot(tweets, aes(x = airline_sentiment, fill = airline_sentiment)) +
geom_bar() +
facet_grid(. ~ airline) +
theme(axis.text.x = element_text(angle=65, vjust=0.6),
plot.margin = unit(c(3,0,3,0), "cm"))
runApp()
runApp()
ggplot(tweets, aes(x = airline_sentiment, fill = airline_sentiment)) +
geom_bar() +
facet_grid(. ~ airline) +
theme(axis.text.x = element_text(angle=65, vjust=0.6),
plot.margin = unit(c(3,0,3,0), "cm"))
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('~/Desktop/Bootcamp/R/shinyApps/shinyDashBoard')
runApp()
runApp()
setwd("~/Desktop/Bootcamp/R/Fred Shiny Project")
runApp()
location = tweets$tweet_coord
location = location[!is.na(location)]
location = as_tibble(location)
location = select(location, location = value)
location$location = as.character(location$location)
location_2 <- location %>%
filter(location != "[0.0, 0.0]") %>%
count(location)
location_coords = strsplit(location_2$location, ',')
lat = NULL
long = NULL
for (i in 1:length(location_coords)) {
lat = c(lat, substring(location_coords[[i]][1], 2)) # removes first character which is [
long = c(long, location_coords[[i]][2])
}
location_2$lat <- lat
location_2$long = long
# remove ]
location_2$long = substr(location_2$long, 1, nchar(location_2$long)-1)
location_2$lat = as.numeric(location_2$lat)
location_2$long = as.numeric(location_2$long)
options(repr.plot.width = 10, repr.plot.height = 7)
require(maps)
world_map <- map_data("world")
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue')+
ggtitle("Location of tweets across the World")+
geom_point(data = location_2, aes(x = long, y = lat, size = n), color="coral1") + scale_size(name="Total Tweets")
location = tweets$tweet_coord
location = location[!is.na(location)]
location = as_tibble(location)
location = select(location, location = value)
location$location = as.character(location$location)
location_2 <- location %>%
filter(location != "[0.0, 0.0]") %>%
count(location)
location_coords = strsplit(location_2$location, ',')
lat = NULL
long = NULL
for (i in 1:length(location_coords)) {
lat = c(lat, substring(location_coords[[i]][1], 2)) # removes first character which is [
long = c(long, location_coords[[i]][2])
}
location_2$lat <- lat
location_2$long = long
# remove ]
location_2$long = substr(location_2$long, 1, nchar(location_2$long)-1)
location_2$lat = as.numeric(location_2$lat)
location_2$long = as.numeric(location_2$long)
options(repr.plot.width = 10, repr.plot.height = 7)
require(maps)
world_map <- map_data("world")
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue')+
ggtitle("Location of tweets across the World")+
geom_point(data = location_2, aes(x = long, y = lat, size = n), color="coral1") + scale_size(name="Total Tweets")
colors=sns.color_palette("hls", 10)
pd.Series(data["airline_sentiment"]).value_counts().plot(kind="pie",colors=colors,labels=["negative", "neutral", "positive"],explode=[0.05,0.02,0.04],shadow=True,autopct='%.2f', fontsize=12,figsize=(6, 6),title = "Total_Airline_Sentiment")
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
colors=sns.color_palette("hls", 10)
pd.Series(data["airline_sentiment"]).value_counts().plot(kind="pie",colors=colors,labels=["negative", "neutral", "positive"],explode=[0.05,0.02,0.04],shadow=True,autopct='%.2f', fontsize=12,figsize=(6, 6),title = "Total_Airline_Sentiment")
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
ggplot(tweets, aes(x = airline, fill = airline_sentiment)) +
geom_bar() +
scale_fill_discrete(name = 'Sentiment') +
ggtitle("Sentiment vs Airline")
runApp()
runApp()
runApp()
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
ggplot(tweets, aes(x = airline, fill = airline_sentiment)) +
geom_bar(position = 'fill') +
scale_fill_discrete(name = 'Sentiment') +
ggtitle("Sentiment vs Airline (persentage)")
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
ggplot(tweets, aes(x = airline, fill = airline_sentiment)) +
geom_bar(position = 'fill') +
scale_fill_discrete(name = 'Sentiment') +
ggtitle("Sentiment vs Airline (persentage)")
ggplot(tweets, aes(x = airline, fill = airline_sentiment)) +
geom_bar(position = 'fill') +
scale_fill_discrete(name = 'Sentiment') +
ggtitle("Sentiment vs Airline (persentage)")
runApp()
ggplot(tweets, aes(x = airline, fill = airline_sentiment)) +
geom_bar(position = 'fill') +
scale_fill_discrete(name = 'Sentiment') +
coord_polar(theta = "y") +
ggtitle("Pie chart: Sentiment vs Airline (persentage)")
runApp()
ggplot(tweets, aes(x = '', fill = airline_sentiment)) +
geom_bar(position = 'fill') +
facet_wrap(~airline, nrow = 2) +
scale_fill_discrete(name = 'Sentiment') +
coord_polar(theta = "y") +
labs(x = '', y = '') +
ggtitle("Pie chart: Sentiment vs Airline (persentage)")
runApp()
leaflet(tweets) %>%
addProviderTiles('OpenMapSurfer.Roads', group = "Roads") %>%
addProviderTiles(providers$CartoDB.Positron, group = 'Hydda.Full') %>%
addCircleMarkers(~lon_tweet_coord, ~lat_tweet_coord, radius = 0.2, col = 'red') %>%
addLayersControl(baseGroups = c("Roads", "Hydda.Full"),
options = layersControlOptions(collapsed = FALSE))
install.packages("leaflet")
library(leaflet)
leaflet(tweets) %>%
addProviderTiles('OpenMapSurfer.Roads', group = "Roads") %>%
addProviderTiles(providers$CartoDB.Positron, group = 'Hydda.Full') %>%
addCircleMarkers(~lon_tweet_coord, ~lat_tweet_coord, radius = 0.2, col = 'red') %>%
addLayersControl(baseGroups = c("Roads", "Hydda.Full"),
options = layersControlOptions(collapsed = FALSE))
sum(is.na(mydata$negativereason_confidence))
mean(mydata$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(mydata,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(mydata), airline=mydata$airline, text = mydata$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
install.packages("Tokenizers")
install.packages("tokenizers")
install.packages("tokenizers")
library(tokenizers)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
install.packages("tokenizers")
runApp()
install.packages("tokenizers")
install.packages("tokenizers")
library(tokenizers)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
library(leaflet)
library(tokenizers)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
grouped_text <- unnest_tokens(text_df,word, text)
install.packages("tidytext")
library(tidytext)
install.packages("tidytext")
install.packages("tidytext")
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
library(leaflet)
library(tokenizers)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
library(ggthemes)
library(grid)
library(tidyr)
install.packages("ggthemes")
install.packages("grid")
install.packages("tidyr")
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
library(leaflet)
library(tokenizers)
library(ggthemes)
library(grid)
library(tidyr)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
runApp()
library(DT)
library(shiny)
library(googleVis)
library(dplyr)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(tm)
library(tidyverse)
library(plotly)
library(maps)
library(rbokeh)
library(widgetframe)
library(htmlwidgets)
library(leaflet)
library(tokenizers)
library(ggthemes)
library(grid)
library(tidyr)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
View(text_df)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(text_df$text,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
class(text_df$text)
sum(is.na(tweets$negativereason_confidence))
mean(tweets$negativereason_confidence, na.rm=TRUE)
by_negativereason_airline <- group_by(tweets,airline)
categorized_negativereason_airline <- summarize (by_negativereason_airline,n=n(),
mn=mean(negativereason_confidence,na.rm = TRUE))
categorized_negativereason_airline
text_df <- data_frame(line = 1:nrow(tweets), airline=tweets$airline, text = tweets$text )
grouped_text <- unnest_tokens(as.character(text_df$text),word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
?unnest_tokens
grouped_text <- unnest_tokens(text_df,word, as.character(text))
grouped_text <- unnest_tokens(text_df,'word', 'text')
text_df$text <- as.character(text_df$text)
grouped_text <- unnest_tokens(text_df,word, text)
##American wordcloud
grouped_text %>% filter(airline == 'American')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
runApp()
runApp()
grouped_text %>% filter(airline == 'Delta')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
grouped_text %>% filter(airline == 'Delta')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
grouped_text %>% filter(airline == 'Delta')%>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
runApp()
runApp()
runApp()
location = tweets$tweet_coord
location = location[!is.na(location)]
location = as_tibble(location)
location = select(location, location = value)
location$location = as.character(location$location)
location_2 <- location %>%
filter(location != "[0.0, 0.0]") %>%
count(location)
location_coords = strsplit(location_2$location, ',')
lat = NULL
long = NULL
for (i in 1:length(location_coords)) {
lat = c(lat, substring(location_coords[[i]][1], 2)) # removes first character which is [
long = c(long, location_coords[[i]][2])
}
location_2$lat <- lat
location_2$long = long
location_2$long = substr(location_2$long, 1, nchar(location_2$long)-1)
location_2$lat = as.numeric(location_2$lat)
location_2$long = as.numeric(location_2$long)
options(repr.plot.width = 10, repr.plot.height = 7)
require(maps)
world_map <- map_data("world")
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue')+
ggtitle("Location of tweets across the World")+
geom_point(data = location_2, aes(x = long, y = lat, size = n), color="coral1") + scale_size(name="Total Tweets")
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue')+
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue')
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue') + ggtitle("Location of tweets across the World")
ggplot()+
geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour="black", fill = 'lightblue')+
ggtitle("Location of tweets across the World")+
geom_point(data = location_2, aes(x = long, y = lat, size = n), color="coral1") + scale_size(name="Total Tweets")
runApp()
View(text_df)
runApp()
